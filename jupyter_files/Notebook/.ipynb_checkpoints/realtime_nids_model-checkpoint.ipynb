{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b84bdc-ac83-4652-a860-de4faddffb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720a6aee-dedb-4da5-8369-6ac017e68b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras import callbacks\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score,classification_report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb741c65-842e-4121-b2b4-4027c6b58212",
   "metadata": {},
   "source": [
    "## Functions define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f746b84-f3f1-41c1-87ae-eb934b288cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It converts categorical data into dummy variables (i.e.one-hot encoding)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ff0d0b-eeb1-4b49-ac00-8b9c3befa3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It encodes categorical values as numerical indexes\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cbb90-d8b1-48f5-9b9b-ccfa3da0f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It prepares the dataset for TensorFlow by separating the target column (y) \n",
    "# from the features (x). If the target is for classification, it performs one-hot encoding; \n",
    "# if it's for regression, it leaves it as a continuous value.\n",
    "\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a509b91-23a1-41ce-93f1-5a5c911d2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It loads the dataset (all_attack_sampled_dataset.csv) from a directory and returns a pandas DataFrame\n",
    "def load_data():\n",
    "    file = \"all_attack_sampled_dataset.csv\"\n",
    "    df1 = pd.read_csv(file)\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bca4e5-8e1f-4461-b097-a738f78d2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  It oversamples the dataset by duplicating minority class rows to balance the dataset\n",
    "def oversample(dfx):\n",
    "    max_size = dfx ['SubLabel'].value_counts().max()\n",
    "    lst = [dfx ]\n",
    "    for class_index, group in dfx .groupby('SubLabel'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    dfx_new = pd.concat(lst)\n",
    "    return dfx_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275a7ae-94d2-48cc-9f89-9bb745cfe702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of the data which includes folowing:\n",
    "# Dropping unnecessary columns\n",
    "# Encodes categorical values in the SubLabel and Label columns\n",
    "# Converts 'Normal' to 0 and 'Attack' to 1 in the Label column\n",
    "def preprocess(df):\n",
    "    print(\"Total number of features : \",len(df.columns))\n",
    "    print(\"\\n----Dropping features---\")\n",
    "    \n",
    "    drop_columns = ['Timestamp','Src IP','Dst IP','Src Port','Flow ID']\n",
    "    df.drop(drop_columns,inplace=True,axis=1)\n",
    "    \n",
    "    print(\"Number of features : \",len(df.columns))\n",
    "    print(\"\\n----Encoding categorical data---\")\n",
    "    \n",
    "    df.loc[df['SubLabel']=='Normal', 'SubLabel'] = 0\n",
    "\n",
    "    df.loc[df['SubLabel']=='Port Scan', 'SubLabel'] = 1\n",
    "    df.loc[df['SubLabel']=='TCP SYN Scan', 'SubLabel'] = 1\n",
    "\n",
    "    df.loc[df['SubLabel']=='DOS goldeneye', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='DOS Slowloris', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='ICMP Flood', 'SubLabel'] = 2\n",
    "    df.loc[df['SubLabel']=='Push ACK Flood', 'SubLabel'] = 2\n",
    "    df.loc[df['SubLabel']=='SYN FIN Flood', 'SubLabel'] = 2\n",
    "    df.loc[df['SubLabel']=='UDP Flood', 'SubLabel'] = 5\n",
    "    \n",
    "    df.loc[df['SubLabel']=='SSH BruteForce', 'SubLabel'] = 3\n",
    "    \n",
    "    df.loc[df['SubLabel']=='Malware Infiltration', 'SubLabel'] = 4\n",
    "\n",
    "\n",
    "    \n",
    "    df.loc[df['SubLabel']=='FTP Bounce Scan', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='Host Scan', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='Xmas Scan', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='ACK Scan', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='FIN Scan', 'SubLabel'] = 5 \n",
    "    df.loc[df['SubLabel']=='FTP Bruteforce', 'SubLabel'] = 5\n",
    "    df.loc[df['SubLabel']=='MySql BruteForce', 'SubLabel'] = 5\n",
    "    \n",
    "   \n",
    "    df = df.drop(df[(df.SubLabel!= 0) & (df.SubLabel!= 1 )& (df.SubLabel!= 2)&(df.SubLabel!= 3)&(df.SubLabel!= 4)].index)\n",
    "\n",
    "    \n",
    "    \n",
    "    # replacing normal by 0 and threat by 1 \n",
    "    df.loc[df['Label']=='Normal', 'Label'] = 0\n",
    "    df.loc[df['Label']=='Attack', 'Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673d50f-ef32-487b-9bde-be741e6dafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcation for visualization of confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3550d6-670c-4909-ab65-04c197c535fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the evaluation of  the model for multiclass classification, showing precision, recall, F1-score, accuracy, and confusion matrix\n",
    "def evaluate_multiclass(y_pred, y_eval, history):\n",
    "    #evaluation\n",
    "    from sklearn import metrics\n",
    "    print(metrics.classification_report(y_eval,y_pred, target_names=['Normal', 'Scan','DOS','Bruteforce','Malware']))\n",
    "    print(f\"Accuracy:{accuracy_score(y_eval,y_pred)*100}%\")\n",
    "    \n",
    "    # Plot normalized confusion matrix\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "    class_names = ['Normal', 'Scan','DOS','Bruteforce','Malware']\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plot_confusion_matrix(cm, classes=class_names, normalize=False,title='CONFUSION MATRIX \\n\\n Multiclass Classification \\n')\n",
    "    plt.show()\n",
    "\n",
    "    #plot model loss\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(history.history['loss'], linewidth=2, label='Train',color = 'Green')\n",
    "    plt.plot(history.history['val_loss'], linewidth=2, label='Valid',color ='Brown')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('MODEL LOSS CURVE')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff805468-f79d-4595-a3a1-b3e544788ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the evaluation of binary classification model (normal vs. a specific attack), showing similar metrics along with the ROC curve and AUC.\n",
    "def evaluate(y_pred, y_eval, history, Attack_name):\n",
    "    \n",
    "    print(f\"Accuracy:{accuracy_score(y_eval,y_pred)*100}%\")\n",
    "    print(f\"Precison:{precision_score(y_eval,y_pred)*100}\")\n",
    "    print(f\"Recall:{recall_score(y_eval,y_pred)*100}\")\n",
    "    print(f\"F1-Score:{f1_score(y_eval, y_pred) *100}\")\n",
    "    \n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "    class_names = ['Normal',Attack_name]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plot_confusion_matrix(cm, classes=class_names, normalize=False,title=f'CONFUSION MATRIX \\n Normal vs {Attack_name} \\n') \n",
    "    plt.show()\n",
    "\n",
    "    # Print ROC curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_eval, y_pred,pos_label=1)\n",
    "    n = 20\n",
    "    x_interp = np.linspace(0,0.1,n+1)\n",
    "    y_interp = spline(fpr, tpr, x_interp, order=1)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title(f'ROC CURVE \\n {Attack_name} Classification \\n')\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.plot(x_interp,y_interp)\n",
    "    plt.show() \n",
    "\n",
    "    # Print AUC\n",
    "    auc = np.trapz(tpr,fpr)\n",
    "    print('AUC:', auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b57db-6bb4-4357-9feb-2524745e3c06",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61d360-4bdb-4673-bb79-adbd67356342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a binary classification model with one hidden layer (54 units) and softmax output for multiclass classification. \n",
    "# It uses early stopping based on validation loss.\n",
    "\n",
    "def dnnmodel(x,y):\n",
    "    \n",
    "    # Split into train/test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1000)\n",
    "\n",
    "\n",
    "    print(\"#### Training and Testing the model ####\")\n",
    "    # Create neural net\n",
    "    model = Sequential()\n",
    "    model.add(Dense(54, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(y.shape[1],activation='softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "    history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"./model/modeldnnattack.keras\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    #predict label\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    y_test = np.argmax(y_test,axis=1)\n",
    "    \n",
    "    return y_pred ,  y_test, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffd14b-2e43-4de3-97d1-b64a67609afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines an LSTM model for multiclass classification. \n",
    "# LSTM layers capture sequential dependencies in data, which is useful for time-series data or sequential inputs.\n",
    "\n",
    "def dnnmodel_multiclass():\n",
    "    x = df1.iloc[:,0:78].values  \n",
    "    y = df1.iloc[:,78:83].values\n",
    "    \n",
    "    #scale using minmaxscalar\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    \n",
    "    # Split into train/test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1000)\n",
    "\n",
    "\n",
    "    print(\"#### Dense Neural Network ####\")\n",
    "    # Create neural net\n",
    "    model = Sequential()\n",
    "    model.add(Dense(x.shape[1], input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(y.shape[1],activation='softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=1, mode='auto')\n",
    "    history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"../models/modeldnnoversample.hdf5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    #predict label\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    y_eval = np.argmax(y_test,axis=1)\n",
    "    \n",
    "    #model summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return y_pred ,  y_eval, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1da19-7f64-45f3-b50a-ff6f4fa9ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a binary classification DNN similar to the multiclass versions but operates on the Label column for binary outcomes.\n",
    "\n",
    "def dnnmodel_binary(df):\n",
    "    \n",
    "    x,y =  to_xy(df,'Label')\n",
    "    \n",
    "    # Split into train/test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1000)\n",
    "\n",
    "\n",
    "    print(\"#### Training and Testing the model ####\")\n",
    "    # Create neural net\n",
    "    model = Sequential()\n",
    "    model.add(Dense(54, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(y.shape[1],activation='softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "    history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"../models/modeltestdnnbinary.hdf5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    #predict label\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    y_test = np.argmax(y_test,axis=1)\n",
    "    \n",
    "    return y_pred ,  y_test, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3436b84-3248-4c8d-8006-62f002dcd9c3",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011dc1f-40a4-4bbf-b93a-73805a0354cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bdefb-f00f-4570-a488-9f4ee87666d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5de37-b1f2-48ed-ba71-431cb92c5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8c7e6-e933-4137-bffb-1420b3e96538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58192b97-4b5d-48ee-a953-71d637441bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label distribution\n",
    "print('Label distribution of data set:')\n",
    "print(df['SubLabel'].value_counts())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651e0dd-0aef-4333-ae12-c5c5a47daf1a",
   "metadata": {},
   "source": [
    "## Step 1 : Preprocessing and encoding of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b2396-fe67-41e5-80a7-5d4cf0edea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data:\",df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272887e8-928d-4eb2-a16b-d3c8695cb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b78c3-7a8b-4032-97f0-d3ca9e2484c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing data type\n",
    "df['Flow Byts/s'] = df['Flow Byts/s'].astype('float32')\n",
    "df['Flow Pkts/s'] = df['Flow Pkts/s'].astype('float32')\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5a248-25b3-414b-bc4a-e2d65c4da71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "print(df['SubLabel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d84a1-2596-4c6a-9c18-e8a850e9427f",
   "metadata": {},
   "source": [
    "# Now splitting the dataset into category of each and every attack type in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1d6d9-263d-468f-8042-5953ae0817e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()\n",
    "df = oversample(df)\n",
    "df1=df.copy()\n",
    "df= df.sample(frac=1).reset_index(drop=True) \n",
    "df1= df1.sample(frac=1).reset_index(drop=True)\n",
    "df1.drop(['Label'], inplace = True , axis=1)\n",
    "df.drop(['SubLabel'], inplace = True , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2a151-a5ed-4179-bc93-612fa2f2362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ea468-bf31-4533-b5d7-e6765c8f9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1d299-49c9-4f82-bc86-8e5263653fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan\n",
    "df_Scan = df1.drop(df1[(df1.SubLabel!= 1) & (df1.SubLabel!= 0)].index)\n",
    "#DOS attack\n",
    "df_DOS = df1.drop(df1[(df1.SubLabel!= 2) & (df1.SubLabel!= 0) ].index)\n",
    "#BruteForce\n",
    "df_SSHBruteForce = df1.drop(df1[(df1.SubLabel!= 3) & (df1.SubLabel!= 0) ].index)\n",
    "#Malware\n",
    "df_Malware = df1.drop(df1[(df1.SubLabel!= 4) & (df1.SubLabel!= 0) ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878261a-1374-4540-a635-c7155e32714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1['SubLabel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23711b-0fad-4fea-aa57-c24225c56619",
   "metadata": {},
   "source": [
    "## Step 2: Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ea8bf-2707-4555-a321-21d2d552b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframes into X & Y\n",
    "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
    "\n",
    "X_Scan,Y_Scan = to_xy(df_Scan,'SubLabel')\n",
    "Y_ScanF = df_Scan.SubLabel\n",
    "\n",
    "X_DOS,Y_DOS = to_xy(df_DOS,'SubLabel')\n",
    "Y_DOSF = df_DOS.SubLabel\n",
    "\n",
    "X_SSHBruteForce,Y_SSHBruteForce = to_xy(df_SSHBruteForce,'SubLabel')\n",
    "Y_SSHBruteForceF = df_SSHBruteForce.SubLabel\n",
    "\n",
    "X_Malware,Y_Malware = to_xy(df_Malware,'SubLabel')\n",
    "Y_MalwareF = df_Malware.SubLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be7208-7bcf-4c84-95b7-e016c0a7cf5d",
   "metadata": {},
   "source": [
    "### Use StandardScaler() to scale the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d8adf-bad1-4629-9463-3555110d18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = preprocessing.StandardScaler().fit(X_Scan)\n",
    "X_Scan = scaler1.transform(X_Scan) \n",
    "\n",
    "scaler2 = preprocessing.StandardScaler().fit(X_DOS)\n",
    "X_DOS = scaler2.transform(X_DOS) \n",
    "\n",
    "scaler3 = preprocessing.StandardScaler().fit(X_SSHBruteForce)\n",
    "X_SSHBruteForce = scaler3.transform(X_SSHBruteForce) \n",
    "\n",
    "scaler4 = preprocessing.StandardScaler().fit(X_Malware)\n",
    "X_Malware = scaler4.transform(X_Malware) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85b0d8-7422-4967-b617-1e54d279199b",
   "metadata": {},
   "source": [
    "## Step 3: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7cfc3-8485-409c-94ea-44ca7a9ce19d",
   "metadata": {},
   "source": [
    "### 1. Univariate Feature Selection using ANOVA F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4dde4-3cb7-49ac-aa7f-03d2533a61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "np.seterr(divide='ignore', invalid='ignore');\n",
    "colNames=list(df1)\n",
    "selector=SelectPercentile(f_classif, percentile=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466179ee-c184-42c2-b5f6-3e81c8aaa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_newScan = selector.fit_transform(X_Scan,Y_ScanF)\n",
    "X_newScan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a5be5-2ce9-41ca-8f01-88625bc441e1",
   "metadata": {},
   "source": [
    "#### Get the features that were selected: Port Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b302915-924a-48d2-8168-f28febeccfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_Scan=[i for i, x in enumerate(true) if x]\n",
    "newcolname_Scan=list( colNames[i] for i in newcolindex_Scan )\n",
    "newcolname_Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908b703-ac9b-40c9-a593-d170adc7d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_newDOS = selector.fit_transform(X_DOS,Y_DOSF)\n",
    "X_newDOS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45800dc-0a28-4a68-9cb9-56c7d0868979",
   "metadata": {},
   "source": [
    "####  Get the features that were selected: DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6004509-3113-4e75-a9c6-5df92ad57eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "newcolname_DoS=list( colNames[i] for i in newcolindex_DoS )\n",
    "newcolname_DoS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4a9ae-8ffc-4f89-99f2-7fccb18c4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_newSSHBruteForce = selector.fit_transform(X_SSHBruteForce ,Y_SSHBruteForceF)\n",
    "X_newSSHBruteForce .shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d9f6d-4f22-43b8-9073-0d38d05edbc1",
   "metadata": {},
   "source": [
    "#### Get the features that were selected: SSHBruteForce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9525e-209f-4ee7-b093-0e425b4e2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_SSHBruteForce =[i for i, x in enumerate(true) if x]\n",
    "newcolname_SSHBruteForce =list( colNames[i] for i in newcolindex_SSHBruteForce  )\n",
    "newcolname_SSHBruteForce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9884d0-27e1-410c-b14c-597fe778661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_newMalware = selector.fit_transform(X_Malware ,Y_MalwareF)\n",
    "X_newMalware.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b94eea-b741-484d-a423-26f0597dac81",
   "metadata": {},
   "source": [
    "#### Get the features that were selected: Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae3411-e76f-4f6f-8557-319646df1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=selector.get_support()\n",
    "newcolindex_Malware =[i for i, x in enumerate(true) if x]\n",
    "newcolname_Malware =list( colNames[i] for i in newcolindex_Malware)\n",
    "newcolname_Malware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb23c3f-172c-4c06-9dd1-47560fa5dcde",
   "metadata": {},
   "source": [
    "### 3. Selecton of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d49ff-38b9-4944-bb4c-a8caca924af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df1.copy()\n",
    "dff = dff[dff.columns.intersection(['Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'TotLen Fwd Pkts',\n",
    "       'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean',\n",
    "       'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min',\n",
    "       'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
    "       'Flow IAT Max', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
    "       'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Min',\n",
    "       'Bwd PSH Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "       'Pkt Len Min', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt',\n",
    "       'ACK Flag Cnt', 'Down/Up Ratio', 'Init Bwd Win Byts', 'Idle Mean',\n",
    "       'Idle Std','SubLabel'])]\n",
    "\n",
    "dff.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229990a2-8e44-4906-aef1-c7ca0085d42a",
   "metadata": {},
   "source": [
    "## Step 4: Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6224b9c-6bf2-4720-89f3-e70edcc47d59",
   "metadata": {},
   "source": [
    "### 1. Model trained for all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b03618-6fcb-4547-a04a-b6d20f04cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Dense Neural Network\n",
    "y_pred_Scan,y_eval_Scan,h_Scan = dnnmodel(X_Scan,Y_Scan)\n",
    "\n",
    "y_pred_DOS,y_eval_DOS,h_DOS = dnnmodel(X_DOS,Y_DOS)\n",
    "\n",
    "y_pred_SSHBruteForce,y_eval_SSHBruteForce,h_SSHBruteForce = dnnmodel(X_SSHBruteForce ,Y_SSHBruteForce )\n",
    "\n",
    "y_pred_Malware,y_eval_Malware,h_Malware = dnnmodel(X_Malware,Y_Malware)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276ac96-9745-4f6e-82bf-f3a86be9f3ba",
   "metadata": {},
   "source": [
    "### 2. Model is trained for selectedd features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39026630-573b-408b-9b37-46a43690da31",
   "metadata": {},
   "source": [
    "### ANOVA Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fba1f-d59c-4b8e-871a-61c15b50e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Dense Neural Network\n",
    "\n",
    "y_pred_newScan,y_eval_newScan,h_newScan = dnnmodel(X_newScan,Y_Scan)\n",
    "\n",
    "y_pred_newDOS,  y_eval_newDOS,h_newDOS = dnnmodel(X_newDOS,Y_DOS)\n",
    "\n",
    "y_pred_newSSHBruteForce,y_eval_newSSHBruteForce,h_newSSHBruteForce = dnnmodel(X_newSSHBruteForce ,Y_SSHBruteForce )\n",
    "\n",
    "y_pred_newMalware,y_eval_newMalware,h_newMalware = dnnmodel(X_newMalware,Y_Malware)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049941d-869b-470e-8c7a-854340ee9fc8",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c0fcb-48d3-4ec3-b4e2-9cf499dab106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Dense Neural Network\n",
    "\n",
    "y_pred_rfeScan,y_eval_rfeScan,h_rfeScan = dnnmodel(X_rfeScan,Y_Scan)\n",
    "\n",
    "y_pred_rfeDOS,y_eval_rfeDOS,h_rfeDOS = dnnmodel(X_rfeDOS,Y_DOS)\n",
    "\n",
    "y_pred_rfeSSHBruteForce,y_eval_rfeSSHBruteForce,h_rfeSSHBruteForce = dnnmodel(X_rfeSSHBruteForce ,Y_SSHBruteForce )\n",
    "\n",
    "y_pred_rfeMalware,y_eval_rfeMalware,h_rfeMalware = dnnmodel(X_rfeMalware,Y_Malware)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975aa14-c7b2-4b9e-846d-36132b1ae0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
